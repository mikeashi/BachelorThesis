\section{Related Work}
HTN planning is a powerful tool for representing and solving complex problems in a hierarchical and modular fashion that has been applied to a wide range of real-world domains. In the context of poker, however, and to the best of our knowledge, HTN planning techniques have never been used before. One of the key tools that were crucial to the development of PokerShark was the extension of the HTN planning framework to incorporate risk awareness and guide the planner using the agent's risk attitude. This approach was studied in detail in previous research \cite{alnazer2019htn} \cite{georgievski2014utility}  \cite{alnazer2022risk} and provided a strong foundation for the development of PokerShark's risk-aware decision-making process.

Over the years, researchers and engineers have attempted to develop AI systems that can compete with human players in the game of poker. One of the first successful AI poker players was Loki and its successor Poki, which used a formula-based betting strategy and were the focus of several research papers \cite{billings_challenge_2002}  \cite{billings1998poker} \cite{papp_dealing_1998} that laid the foundation for later work, including the development of PokerShark. Other attempts used rule-based expert systems, such as SoarBot \cite{follek2003soarbot}, which have a similar structure to PokerShark, particularly in the way it relies on expert knowledge. There were also other approaches that used different strategies, such as simulations, game theory strategies, and neural networks, with varying degrees of success. In recent years, the success of AI poker players such as Libratus \cite{brown2018superhuman} and Pluribus \cite{blair2019ai} has demonstrated the effectiveness of using CFR for playing poker.

\section{Conclusion}
Developing a strong AI poker player involves many challenges, including decision-making under uncertainty, risk management, game theory, and understanding the behavior and psychology of the opponents. PokerShark succeeded in overcoming some of these challenges resulting in a mediocre poker player with great potential for improvement.
We have successfully modeled the domain using HTN planning constructs and integrated risk awareness into the planning process. Along the way, we have implemented guidelines provided by the domain experts and tried to create an agent that uses different metrics to estimate the cost of its actions. Despite our efforts to find a good balance while integrating risk awareness into the agent decision-making process, we found that our reliance on arbitrary thresholds based on intuition and limited knowledge of the game often led to suboptimal solutions. This was evident in the experiments we conducted, which showed that our dynamic risk attitude performed worse on average than other static attitudes. We have also resorted to using approximation and interpolation to estimate values that are computationally too hard to calculate. The opponent modeling mechanism that PokerShark uses relies on a small number of states, and it only delivers information about the ranges that the opponents like to play. However, it does not take into account important factors such as player position, pot size, and deception. Furthermore, the overall strategy of PokerShark is centered around hand strength, which might not be the best strategy for playing the game. Game theory is still unable to deliver an optimal strategy for poker, but we believe the strategy we have implemented can be vastly improved by adopting tactics that place a greater emphasis on deception and opponent psychology.

Despite the aforementioned shortcomings, the aim of this study was not to create the best poker player but rather to explore the potential of HTN planning in a complex domain such as poker. While PokerShark may not be the most skilled poker player, we believe it demonstrates the effectiveness of using HTN planning with risk awareness as a foundation for building powerful AI agents capable of playing poker efficiently.